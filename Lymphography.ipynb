{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Lymphography Dataset](https://archive.ics.uci.edu/dataset/63/lymphography)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lymphography domain was obtained from the University Medical Centre, Institute of Oncology, Ljubljana, Yugoslavia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrutura do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Alvo  | Valores |\n",
    "| ------------- | ------------- |\n",
    "|class| {normal find, metastases, malign lymph, fibrosis}| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Features  | Valores |\n",
    "| ------------- | ------------- |\n",
    "|lymphatics| { normal, arched, deformed, displaced} |\n",
    "|block of affere| { no, yes} |\n",
    "|bl. of lymph. c| { no, yes} |\n",
    "|bl. of lymph. s| { no, yes} |\n",
    "|by pass| { no, yes} |\n",
    "|extravasates| { no, yes} |\n",
    "|regeneration of| { no, yes} |\n",
    "|early uptake in| { no, yes} |\n",
    "|lym.nodes dimin| { 0-3} |\n",
    "|lym.nodes enlar| { 1-4} |\n",
    "|changes in lym.| { bean, oval, round} |\n",
    "|defect in node| { no, lacunar, lac. marginal, lac. central} |\n",
    "|changes in node| { no, lacunar, lac. margin, lac. central} |\n",
    "|changes in stru| { no, grainy, drop-like, coarse, diluted, reticular, stripped, faint,} |\n",
    "|special forms| { no, chalices, vesicles} |\n",
    "|dislocation of| { no, yes} |\n",
    "|exclusion of no| { no, yes} |\n",
    "|no. of nodes in| { 0-9, 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, >=7} |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalação das dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ucimlrepo\n",
    "# !pip install tensorflow\n",
    "# !pip install sklearn\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "dataset = fetch_ucirepo(id=63) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = dataset.data.features \n",
    "Y = dataset.data.targets \n",
    "\n",
    "# Transform labels to int\n",
    "labels = Y[\"class\"].unique()\n",
    "for i in range(len(labels)):\n",
    "  Y.loc[Y['class']==labels[i], 'class'] = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_fatures = [feature for feature in dataset.data.features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X,columns=cat_fatures, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo os conjuntos de teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size= 0.3, random_state = 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Enconding dos Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train) \n",
    "y_true = list(y_test['class'])\n",
    "y_test = to_categorical(y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    Flatten(input_shape=(len(X.columns),)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5), # Camada de Dropout utilizada para diminuir o overfitting\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(y_train[0]), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_76 (Flatten)        (None, 63)                0         \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 64)                4096      \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_260 (Dense)           (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6308 (24.64 KB)\n",
      "Trainable params: 6308 (24.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "  loss='categorical_crossentropy', \n",
    "  optimizer='adam', \n",
    "  metrics=['Accuracy', 'Precision', 'Recall', 'F1Score']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class stopAtLossValue(Callback):\n",
    "    '''\n",
    "    Funcao utilizada para parar o treinamento caso a loss fique abaixo de um limite estabelecido.\n",
    "\n",
    "    Esta medida foi tomada para diminuir o overfitting que o modelo estava apresentando.\n",
    "\n",
    "    fonte: https://stackoverflow.com/a/54959664\n",
    "    '''\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        THR = 0.01\n",
    "        if logs.get('loss') <= THR:\n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 6ms/step - loss: 1.5763 - Accuracy: 0.1165 - precision: 0.0500 - recall: 0.0097 - f1_score: 0.0796\n",
      "Epoch 2/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5299 - Accuracy: 0.0971 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.0820\n",
      "Epoch 3/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4013 - Accuracy: 0.1942 - precision: 0.5000 - recall: 0.0097 - f1_score: 0.1224    \n",
      "Epoch 4/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.3543 - Accuracy: 0.2233 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_score: 0.1455\n",
      "Epoch 5/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2512 - Accuracy: 0.3883 - precision: 0.5000 - recall: 0.0194 - f1_score: 0.2229\n",
      "Epoch 6/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.1775 - Accuracy: 0.4466 - precision: 0.6667 - recall: 0.0777 - f1_score: 0.2407\n",
      "Epoch 7/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.1401 - Accuracy: 0.4854 - precision: 0.8571 - recall: 0.0583 - f1_score: 0.2568\n",
      "Epoch 8/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0785 - Accuracy: 0.5243 - precision: 0.6429 - recall: 0.0874 - f1_score: 0.2669\n",
      "Epoch 9/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9703 - Accuracy: 0.6311 - precision: 0.8095 - recall: 0.1650 - f1_score: 0.3163\n",
      "Epoch 10/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9632 - Accuracy: 0.6117 - precision: 0.7857 - recall: 0.2136 - f1_score: 0.3100\n",
      "Epoch 11/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8939 - Accuracy: 0.6408 - precision: 0.8889 - recall: 0.3107 - f1_score: 0.3252\n",
      "Epoch 12/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8892 - Accuracy: 0.6408 - precision: 0.7838 - recall: 0.2816 - f1_score: 0.3218\n",
      "Epoch 13/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8022 - Accuracy: 0.6699 - precision: 0.8000 - recall: 0.3883 - f1_score: 0.3240\n",
      "Epoch 14/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7991 - Accuracy: 0.6893 - precision: 0.7193 - recall: 0.3981 - f1_score: 0.3408\n",
      "Epoch 15/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7894 - Accuracy: 0.6019 - precision: 0.7077 - recall: 0.4466 - f1_score: 0.2946\n",
      "Epoch 16/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7354 - Accuracy: 0.6602 - precision: 0.7714 - recall: 0.5243 - f1_score: 0.3222\n",
      "Epoch 17/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6924 - Accuracy: 0.7670 - precision: 0.8378 - recall: 0.6019 - f1_score: 0.3795\n",
      "Epoch 18/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6302 - Accuracy: 0.7961 - precision: 0.8313 - recall: 0.6699 - f1_score: 0.3951\n",
      "Epoch 19/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6395 - Accuracy: 0.7573 - precision: 0.8046 - recall: 0.6796 - f1_score: 0.3721\n",
      "Epoch 20/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6382 - Accuracy: 0.7573 - precision: 0.8313 - recall: 0.6699 - f1_score: 0.3776\n",
      "Epoch 21/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5966 - Accuracy: 0.8155 - precision: 0.8315 - recall: 0.7184 - f1_score: 0.4056\n",
      "Epoch 22/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5769 - Accuracy: 0.7961 - precision: 0.8229 - recall: 0.7670 - f1_score: 0.3918\n",
      "Epoch 23/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6074 - Accuracy: 0.8058 - precision: 0.8144 - recall: 0.7670 - f1_score: 0.4027\n",
      "Epoch 24/600\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5198 - Accuracy: 0.8155 - precision: 0.8495 - recall: 0.7670 - f1_score: 0.4075\n",
      "Epoch 25/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5034 - Accuracy: 0.8544 - precision: 0.8842 - recall: 0.8155 - f1_score: 0.4265\n",
      "Epoch 26/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4501 - Accuracy: 0.8738 - precision: 0.8866 - recall: 0.8350 - f1_score: 0.4383\n",
      "Epoch 27/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5157 - Accuracy: 0.8447 - precision: 0.8660 - recall: 0.8155 - f1_score: 0.4225\n",
      "Epoch 28/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4712 - Accuracy: 0.8350 - precision: 0.8571 - recall: 0.8155 - f1_score: 0.4178\n",
      "Epoch 29/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4996 - Accuracy: 0.8641 - precision: 0.8878 - recall: 0.8447 - f1_score: 0.4335\n",
      "Epoch 30/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4526 - Accuracy: 0.8544 - precision: 0.8529 - recall: 0.8447 - f1_score: 0.4286\n",
      "Epoch 31/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4583 - Accuracy: 0.8350 - precision: 0.8571 - recall: 0.8155 - f1_score: 0.4185\n",
      "Epoch 32/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4860 - Accuracy: 0.8252 - precision: 0.8333 - recall: 0.8252 - f1_score: 0.4123\n",
      "Epoch 33/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4608 - Accuracy: 0.8350 - precision: 0.8416 - recall: 0.8252 - f1_score: 0.4170\n",
      "Epoch 34/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4110 - Accuracy: 0.8641 - precision: 0.8788 - recall: 0.8447 - f1_score: 0.4327\n",
      "Epoch 35/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3783 - Accuracy: 0.8932 - precision: 0.9109 - recall: 0.8932 - f1_score: 0.4481\n",
      "Epoch 36/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3355 - Accuracy: 0.9126 - precision: 0.9200 - recall: 0.8932 - f1_score: 0.4584\n",
      "Epoch 37/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4265 - Accuracy: 0.8252 - precision: 0.8317 - recall: 0.8155 - f1_score: 0.4106\n",
      "Epoch 38/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3500 - Accuracy: 0.8738 - precision: 0.8900 - recall: 0.8641 - f1_score: 0.4381\n",
      "Epoch 39/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3602 - Accuracy: 0.8738 - precision: 0.9247 - recall: 0.8350 - f1_score: 0.4381\n",
      "Epoch 40/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3748 - Accuracy: 0.8738 - precision: 0.8800 - recall: 0.8544 - f1_score: 0.4387\n",
      "Epoch 41/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3813 - Accuracy: 0.8447 - precision: 0.8700 - recall: 0.8447 - f1_score: 0.4238\n",
      "Epoch 42/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3371 - Accuracy: 0.8932 - precision: 0.8922 - recall: 0.8835 - f1_score: 0.4487\n",
      "Epoch 43/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3229 - Accuracy: 0.8835 - precision: 0.9000 - recall: 0.8738 - f1_score: 0.4449\n",
      "Epoch 44/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3515 - Accuracy: 0.8641 - precision: 0.8800 - recall: 0.8544 - f1_score: 0.4340\n",
      "Epoch 45/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3318 - Accuracy: 0.8835 - precision: 0.8911 - recall: 0.8738 - f1_score: 0.4435\n",
      "Epoch 46/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2981 - Accuracy: 0.8835 - precision: 0.8824 - recall: 0.8738 - f1_score: 0.6081\n",
      "Epoch 47/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3300 - Accuracy: 0.8835 - precision: 0.9082 - recall: 0.8641 - f1_score: 0.4435\n",
      "Epoch 48/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3608 - Accuracy: 0.8932 - precision: 0.9000 - recall: 0.8738 - f1_score: 0.4495\n",
      "Epoch 49/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3748 - Accuracy: 0.8932 - precision: 0.9010 - recall: 0.8835 - f1_score: 0.4481\n",
      "Epoch 50/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3298 - Accuracy: 0.9126 - precision: 0.9091 - recall: 0.8738 - f1_score: 0.7036\n",
      "Epoch 51/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3138 - Accuracy: 0.8835 - precision: 0.8990 - recall: 0.8641 - f1_score: 0.4435\n",
      "Epoch 52/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2830 - Accuracy: 0.9029 - precision: 0.9118 - recall: 0.9029 - f1_score: 0.4551\n",
      "Epoch 53/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3561 - Accuracy: 0.8544 - precision: 0.8614 - recall: 0.8447 - f1_score: 0.4296\n",
      "Epoch 54/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3470 - Accuracy: 0.8738 - precision: 0.8824 - recall: 0.8738 - f1_score: 0.4400\n",
      "Epoch 55/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3156 - Accuracy: 0.8544 - precision: 0.8800 - recall: 0.8544 - f1_score: 0.4296\n",
      "Epoch 56/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3327 - Accuracy: 0.8544 - precision: 0.8700 - recall: 0.8447 - f1_score: 0.5923\n",
      "Epoch 57/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2836 - Accuracy: 0.9029 - precision: 0.9118 - recall: 0.9029 - f1_score: 0.6184\n",
      "Epoch 58/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2765 - Accuracy: 0.9320 - precision: 0.9307 - recall: 0.9126 - f1_score: 0.6331\n",
      "Epoch 59/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2446 - Accuracy: 0.9126 - precision: 0.9293 - recall: 0.8932 - f1_score: 0.4588\n",
      "Epoch 60/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2757 - Accuracy: 0.8932 - precision: 0.9020 - recall: 0.8932 - f1_score: 0.4504\n",
      "Epoch 61/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2830 - Accuracy: 0.9223 - precision: 0.9208 - recall: 0.9029 - f1_score: 0.6270\n",
      "Epoch 62/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2965 - Accuracy: 0.8835 - precision: 0.8922 - recall: 0.8835 - f1_score: 0.6074\n",
      "Epoch 63/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2541 - Accuracy: 0.9126 - precision: 0.9208 - recall: 0.9029 - f1_score: 0.6229\n",
      "Epoch 64/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2868 - Accuracy: 0.9126 - precision: 0.9192 - recall: 0.8835 - f1_score: 0.7040\n",
      "Epoch 65/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2491 - Accuracy: 0.9029 - precision: 0.9100 - recall: 0.8835 - f1_score: 0.6176\n",
      "Epoch 66/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2742 - Accuracy: 0.9126 - precision: 0.9118 - recall: 0.9029 - f1_score: 0.7032\n",
      "Epoch 67/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2595 - Accuracy: 0.9126 - precision: 0.9300 - recall: 0.9029 - f1_score: 0.4595\n",
      "Epoch 68/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2372 - Accuracy: 0.9223 - precision: 0.9223 - recall: 0.9223 - f1_score: 0.6289\n",
      "Epoch 69/600\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2778 - Accuracy: 0.9029 - precision: 0.9184 - recall: 0.8738 - f1_score: 0.6171\n",
      "Epoch 70/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2370 - Accuracy: 0.9126 - precision: 0.9394 - recall: 0.9029 - f1_score: 0.6237\n",
      "Epoch 71/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2279 - Accuracy: 0.9417 - precision: 0.9412 - recall: 0.9320 - f1_score: 0.7192\n",
      "Epoch 72/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2589 - Accuracy: 0.9223 - precision: 0.9223 - recall: 0.9223 - f1_score: 0.7086\n",
      "Epoch 73/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2124 - Accuracy: 0.9029 - precision: 0.9020 - recall: 0.8932 - f1_score: 0.6987\n",
      "Epoch 74/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2557 - Accuracy: 0.9223 - precision: 0.9223 - recall: 0.9223 - f1_score: 0.6278\n",
      "Epoch 75/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2734 - Accuracy: 0.8835 - precision: 0.8922 - recall: 0.8835 - f1_score: 0.6889\n",
      "Epoch 76/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2484 - Accuracy: 0.9126 - precision: 0.9126 - recall: 0.9126 - f1_score: 0.7032\n",
      "Epoch 77/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2741 - Accuracy: 0.9223 - precision: 0.9223 - recall: 0.9223 - f1_score: 0.7086\n",
      "Epoch 78/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2759 - Accuracy: 0.9029 - precision: 0.9029 - recall: 0.9029 - f1_score: 0.6991\n",
      "Epoch 79/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1959 - Accuracy: 0.9417 - precision: 0.9412 - recall: 0.9320 - f1_score: 0.7192\n",
      "Epoch 80/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2207 - Accuracy: 0.9320 - precision: 0.9406 - recall: 0.9223 - f1_score: 0.7139\n",
      "Epoch 81/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2123 - Accuracy: 0.9029 - precision: 0.9118 - recall: 0.9029 - f1_score: 0.6987\n",
      "Epoch 82/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2164 - Accuracy: 0.9223 - precision: 0.9314 - recall: 0.9223 - f1_score: 0.7086\n",
      "Epoch 83/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2363 - Accuracy: 0.9223 - precision: 0.9223 - recall: 0.9223 - f1_score: 0.7086\n",
      "Epoch 84/600\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2527 - Accuracy: 0.9029 - precision: 0.9118 - recall: 0.9029 - f1_score: 0.6171\n",
      "Epoch 85/600\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2065 - Accuracy: 0.9223 - precision: 0.9406 - recall: 0.9223 - f1_score: 0.6278\n",
      "Epoch 86/600\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2442 - Accuracy: 0.9320 - precision: 0.9314 - recall: 0.9223 - f1_score: 0.7142\n",
      "Epoch 87/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2519 - Accuracy: 0.9223 - precision: 0.9314 - recall: 0.9223 - f1_score: 0.6278\n",
      "Epoch 88/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2074 - Accuracy: 0.9515 - precision: 0.9505 - recall: 0.9320 - f1_score: 0.7244\n",
      "Epoch 89/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2378 - Accuracy: 0.9029 - precision: 0.9029 - recall: 0.9029 - f1_score: 0.6187\n",
      "Epoch 90/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1717 - Accuracy: 0.9417 - precision: 0.9510 - recall: 0.9417 - f1_score: 0.7192\n",
      "Epoch 91/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1880 - Accuracy: 0.9417 - precision: 0.9600 - recall: 0.9320 - f1_score: 0.4746\n",
      "Epoch 92/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1888 - Accuracy: 0.9320 - precision: 0.9320 - recall: 0.9320 - f1_score: 0.7145\n",
      "Epoch 93/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2370 - Accuracy: 0.9320 - precision: 0.9293 - recall: 0.8932 - f1_score: 0.7139\n",
      "Epoch 94/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1471 - Accuracy: 0.9515 - precision: 0.9703 - recall: 0.9515 - f1_score: 0.4806\n",
      "Epoch 95/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1945 - Accuracy: 0.9612 - precision: 0.9706 - recall: 0.9612 - f1_score: 0.6485\n",
      "Epoch 96/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1866 - Accuracy: 0.9223 - precision: 0.9223 - recall: 0.9223 - f1_score: 0.7086\n",
      "Epoch 97/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1613 - Accuracy: 0.9515 - precision: 0.9515 - recall: 0.9515 - f1_score: 0.7242\n",
      "Epoch 98/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1204 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7345\n",
      "Epoch 99/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1846 - Accuracy: 0.9223 - precision: 0.9216 - recall: 0.9126 - f1_score: 0.7082\n",
      "Epoch 100/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1617 - Accuracy: 0.9417 - precision: 0.9417 - recall: 0.9417 - f1_score: 0.7194\n",
      "Epoch 101/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1884 - Accuracy: 0.9417 - precision: 0.9505 - recall: 0.9320 - f1_score: 0.6712\n",
      "Epoch 102/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2096 - Accuracy: 0.9320 - precision: 0.9406 - recall: 0.9223 - f1_score: 0.7139\n",
      "Epoch 103/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1397 - Accuracy: 0.9515 - precision: 0.9604 - recall: 0.9417 - f1_score: 0.7242\n",
      "Epoch 104/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1804 - Accuracy: 0.9417 - precision: 0.9400 - recall: 0.9126 - f1_score: 0.6389\n",
      "Epoch 105/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1845 - Accuracy: 0.9515 - precision: 0.9510 - recall: 0.9417 - f1_score: 0.7242\n",
      "Epoch 106/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1719 - Accuracy: 0.9417 - precision: 0.9417 - recall: 0.9417 - f1_score: 0.7192\n",
      "Epoch 107/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1531 - Accuracy: 0.9417 - precision: 0.9417 - recall: 0.9417 - f1_score: 0.7192\n",
      "Epoch 108/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1942 - Accuracy: 0.9223 - precision: 0.9216 - recall: 0.9126 - f1_score: 0.7092\n",
      "Epoch 109/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1367 - Accuracy: 0.9612 - precision: 0.9604 - recall: 0.9417 - f1_score: 0.7295\n",
      "Epoch 110/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1643 - Accuracy: 0.9320 - precision: 0.9320 - recall: 0.9320 - f1_score: 0.7142\n",
      "Epoch 111/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1729 - Accuracy: 0.9515 - precision: 0.9515 - recall: 0.9515 - f1_score: 0.7244\n",
      "Epoch 112/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2033 - Accuracy: 0.9515 - precision: 0.9515 - recall: 0.9515 - f1_score: 0.7242\n",
      "Epoch 113/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1199 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7293\n",
      "Epoch 114/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1446 - Accuracy: 0.9515 - precision: 0.9515 - recall: 0.9515 - f1_score: 0.7244\n",
      "Epoch 115/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1287 - Accuracy: 0.9417 - precision: 0.9417 - recall: 0.9417 - f1_score: 0.7190\n",
      "Epoch 116/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1377 - Accuracy: 0.9515 - precision: 0.9608 - recall: 0.9515 - f1_score: 0.7242\n",
      "Epoch 117/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1600 - Accuracy: 0.9417 - precision: 0.9417 - recall: 0.9417 - f1_score: 0.7192\n",
      "Epoch 118/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1486 - Accuracy: 0.9417 - precision: 0.9417 - recall: 0.9417 - f1_score: 0.7194\n",
      "Epoch 119/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1460 - Accuracy: 0.9417 - precision: 0.9510 - recall: 0.9417 - f1_score: 0.7192\n",
      "Epoch 120/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1295 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7345\n",
      "Epoch 121/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1030 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 122/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1546 - Accuracy: 0.9417 - precision: 0.9510 - recall: 0.9417 - f1_score: 0.7190\n",
      "Epoch 123/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1706 - Accuracy: 0.9417 - precision: 0.9505 - recall: 0.9320 - f1_score: 0.7190\n",
      "Epoch 124/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1363 - Accuracy: 0.9417 - precision: 0.9417 - recall: 0.9417 - f1_score: 0.7192\n",
      "Epoch 125/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1532 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7293\n",
      "Epoch 126/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1598 - Accuracy: 0.9417 - precision: 0.9417 - recall: 0.9417 - f1_score: 0.7190\n",
      "Epoch 127/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1164 - Accuracy: 0.9612 - precision: 0.9608 - recall: 0.9515 - f1_score: 0.7295\n",
      "Epoch 128/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1114 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7345\n",
      "Epoch 129/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1369 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7296\n",
      "Epoch 130/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1609 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7295\n",
      "Epoch 131/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1167 - Accuracy: 0.9806 - precision: 0.9802 - recall: 0.9612 - f1_score: 0.7398\n",
      "Epoch 132/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1322 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7296\n",
      "Epoch 133/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1188 - Accuracy: 0.9515 - precision: 0.9510 - recall: 0.9417 - f1_score: 0.6440\n",
      "Epoch 134/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1141 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7293\n",
      "Epoch 135/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1153 - Accuracy: 0.9612 - precision: 0.9706 - recall: 0.9612 - f1_score: 0.7295\n",
      "Epoch 136/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0906 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7345\n",
      "Epoch 137/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1029 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 138/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1288 - Accuracy: 0.9612 - precision: 0.9608 - recall: 0.9515 - f1_score: 0.7295\n",
      "Epoch 139/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0886 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7345\n",
      "Epoch 140/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1133 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7347\n",
      "Epoch 141/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1206 - Accuracy: 0.9612 - precision: 0.9608 - recall: 0.9515 - f1_score: 0.7295\n",
      "Epoch 142/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1252 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7296\n",
      "Epoch 143/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0887 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7398\n",
      "Epoch 144/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1132 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.6494\n",
      "Epoch 145/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1024 - Accuracy: 0.9515 - precision: 0.9515 - recall: 0.9515 - f1_score: 0.7242\n",
      "Epoch 146/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1037 - Accuracy: 0.9612 - precision: 0.9706 - recall: 0.9612 - f1_score: 0.7298\n",
      "Epoch 147/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1005 - Accuracy: 0.9515 - precision: 0.9515 - recall: 0.9515 - f1_score: 0.6443\n",
      "Epoch 148/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0890 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 149/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1118 - Accuracy: 0.9709 - precision: 0.9800 - recall: 0.9515 - f1_score: 0.7345\n",
      "Epoch 150/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0920 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7345\n",
      "Epoch 151/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0919 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7298\n",
      "Epoch 152/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0977 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7347\n",
      "Epoch 153/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0828 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7345\n",
      "Epoch 154/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1112 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7293\n",
      "Epoch 155/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0655 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 156/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1037 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7347\n",
      "Epoch 157/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0995 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7295\n",
      "Epoch 158/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0832 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7347\n",
      "Epoch 159/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0960 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7295\n",
      "Epoch 160/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1306 - Accuracy: 0.9320 - precision: 0.9320 - recall: 0.9320 - f1_score: 0.4694\n",
      "Epoch 161/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0846 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7345\n",
      "Epoch 162/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0920 - Accuracy: 0.9612 - precision: 0.9703 - recall: 0.9515 - f1_score: 0.7293\n",
      "Epoch 163/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0719 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 164/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1038 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7295\n",
      "Epoch 165/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0796 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 166/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0934 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.6485\n",
      "Epoch 167/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1024 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.6866\n",
      "Epoch 168/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0731 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 169/600\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1009 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7295\n",
      "Epoch 170/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0647 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 171/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0753 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7348\n",
      "Epoch 172/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0988 - Accuracy: 0.9515 - precision: 0.9604 - recall: 0.9417 - f1_score: 0.6433\n",
      "Epoch 173/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0677 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 174/600\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0919 - Accuracy: 0.9417 - precision: 0.9510 - recall: 0.9417 - f1_score: 0.6383\n",
      "Epoch 175/600\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0837 - Accuracy: 0.9806 - precision: 0.9804 - recall: 0.9709 - f1_score: 0.7398\n",
      "Epoch 176/600\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0605 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 177/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0799 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 178/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0833 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7347\n",
      "Epoch 179/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0837 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.6492\n",
      "Epoch 180/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0662 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7398\n",
      "Epoch 181/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0791 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7345\n",
      "Epoch 182/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0593 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 183/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0502 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 184/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0621 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 185/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0716 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 186/600\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0619 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.6544\n",
      "Epoch 187/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0664 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 188/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0690 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7398\n",
      "Epoch 189/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0535 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 190/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0506 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 191/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0752 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7345\n",
      "Epoch 192/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1024 - Accuracy: 0.9612 - precision: 0.9706 - recall: 0.9612 - f1_score: 0.6492\n",
      "Epoch 193/600\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0417 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 194/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0611 - Accuracy: 0.9806 - precision: 0.9804 - recall: 0.9709 - f1_score: 0.7397\n",
      "Epoch 195/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0701 - Accuracy: 0.9806 - precision: 0.9804 - recall: 0.9709 - f1_score: 0.7399\n",
      "Epoch 196/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0448 - Accuracy: 1.0000 - precision: 1.0000 - recall: 0.9903 - f1_score: 0.7500\n",
      "Epoch 197/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0579 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 198/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0677 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7398\n",
      "Epoch 199/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0583 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 200/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0418 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 201/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0613 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 202/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0484 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 203/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0455 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 204/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0905 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7295\n",
      "Epoch 205/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0671 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7347\n",
      "Epoch 206/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0768 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 207/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0624 - Accuracy: 0.9806 - precision: 0.9804 - recall: 0.9709 - f1_score: 0.7397\n",
      "Epoch 208/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0362 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 209/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0734 - Accuracy: 0.9709 - precision: 0.9706 - recall: 0.9612 - f1_score: 0.7347\n",
      "Epoch 210/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0498 - Accuracy: 0.9903 - precision: 0.9902 - recall: 0.9806 - f1_score: 0.7449\n",
      "Epoch 211/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0434 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 212/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0614 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7345\n",
      "Epoch 213/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0541 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 214/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0464 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 215/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0383 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 216/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0451 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 217/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0407 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 218/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0445 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 219/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0561 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.6595\n",
      "Epoch 220/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0793 - Accuracy: 0.9612 - precision: 0.9706 - recall: 0.9612 - f1_score: 0.7295\n",
      "Epoch 221/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0581 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.6586\n",
      "Epoch 222/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0442 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 223/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1024 - Accuracy: 0.9515 - precision: 0.9515 - recall: 0.9515 - f1_score: 0.7242\n",
      "Epoch 224/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0699 - Accuracy: 0.9612 - precision: 0.9612 - recall: 0.9612 - f1_score: 0.7296\n",
      "Epoch 225/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0420 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 226/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0424 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 227/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0615 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 228/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0532 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7398\n",
      "Epoch 229/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0496 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 230/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0248 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 231/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0554 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7398\n",
      "Epoch 232/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0410 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 233/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0477 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 234/600\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0443 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 235/600\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0406 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 236/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0656 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7398\n",
      "Epoch 237/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0544 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 238/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0453 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 239/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0405 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7398\n",
      "Epoch 240/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0253 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 241/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0374 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7398\n",
      "Epoch 242/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0377 - Accuracy: 0.9903 - precision: 1.0000 - recall: 0.9903 - f1_score: 0.6637\n",
      "Epoch 243/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0300 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 244/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0299 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 245/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0271 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 246/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0263 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 247/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0505 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 248/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0388 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7345\n",
      "Epoch 249/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0448 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 250/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0335 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 251/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0406 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 252/600\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0262 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 253/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0242 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 254/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0353 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 255/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0374 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.6637\n",
      "Epoch 256/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0359 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 257/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0463 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 258/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0475 - Accuracy: 0.9806 - precision: 0.9902 - recall: 0.9806 - f1_score: 0.6586\n",
      "Epoch 259/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0368 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 260/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0364 - Accuracy: 0.9806 - precision: 0.9804 - recall: 0.9709 - f1_score: 0.7397\n",
      "Epoch 261/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0498 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 262/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0259 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 263/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0437 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 264/600\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0383 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 265/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0341 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 266/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0343 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 267/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0281 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 268/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0342 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 269/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0319 - Accuracy: 1.0000 - precision: 1.0000 - recall: 0.9903 - f1_score: 0.7500\n",
      "Epoch 270/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0296 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 271/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0283 - Accuracy: 1.0000 - precision: 1.0000 - recall: 0.9903 - f1_score: 0.7500\n",
      "Epoch 272/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0335 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 273/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0423 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 274/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0256 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 275/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0597 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7398\n",
      "Epoch 276/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0435 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 277/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0230 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 278/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0375 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 279/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0293 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 280/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0682 - Accuracy: 0.9806 - precision: 0.9902 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 281/600\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0427 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 282/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0482 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 283/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0337 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 284/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0590 - Accuracy: 0.9709 - precision: 0.9706 - recall: 0.9612 - f1_score: 0.7347\n",
      "Epoch 285/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0169 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 286/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0141 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 287/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0245 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 288/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0388 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.6637\n",
      "Epoch 289/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0390 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.6646\n",
      "Epoch 290/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0205 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 291/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0424 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7398\n",
      "Epoch 292/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0318 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 293/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0272 - Accuracy: 0.9903 - precision: 1.0000 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 294/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0353 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 295/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0392 - Accuracy: 0.9806 - precision: 0.9804 - recall: 0.9709 - f1_score: 0.7398\n",
      "Epoch 296/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0275 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 297/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0484 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7397\n",
      "Epoch 298/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0301 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 299/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0235 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 300/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0389 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 301/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0288 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 302/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0237 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 303/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0179 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 304/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0166 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 305/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0296 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7398\n",
      "Epoch 306/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0180 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 307/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0271 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 308/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0270 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 309/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0175 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 310/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0332 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 311/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0134 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 312/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0606 - Accuracy: 0.9709 - precision: 0.9709 - recall: 0.9709 - f1_score: 0.7347\n",
      "Epoch 313/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0460 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.7398\n",
      "Epoch 314/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0176 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 315/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0136 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 316/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0321 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 317/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0359 - Accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - f1_score: 0.6595\n",
      "Epoch 318/600\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0230 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 319/600\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0283 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 320/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0137 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 321/600\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0185 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 322/600\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0703 - Accuracy: 0.9709 - precision: 0.9706 - recall: 0.9612 - f1_score: 0.7345\n",
      "Epoch 323/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0180 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 324/600\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0171 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 325/600\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0173 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 326/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0274 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.6637\n",
      "Epoch 327/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0195 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 328/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0204 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 329/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0182 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 330/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0258 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.7500\n",
      "Epoch 331/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0383 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 332/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0367 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 333/600\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0282 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 334/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0320 - Accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - f1_score: 0.7449\n",
      "Epoch 335/600\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0099 - Accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1_score: 0.5000\n",
      "2/2 - 0s - loss: 1.2226 - Accuracy: 0.8000 - precision: 0.8000 - recall: 0.8000 - f1_score: 0.5683 - 226ms/epoch - 113ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2226308584213257,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " array([0.78048784, 0.        , 0.6666667 , 0.826087  ], dtype=float32)]"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=600, batch_size=64, verbose=1, callbacks=[stopAtLossValue()])\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions = [list(p).index(max(p)) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia obtida: 80.00%\n",
      "Precisão obtida: 86.36%\n",
      "Recall obtido: 71.13%\n",
      "F1 Score obtida: 75.77%\n"
     ]
    }
   ],
   "source": [
    "print(f'Acurácia obtida: {accuracy_score(y_true, predictions) * 100:.2f}%')\n",
    "print(f'Precisão obtida: {precision_score(y_true, predictions, average=\"macro\", zero_division=np.nan) * 100:.2f}%')\n",
    "print(f'Recall obtido: {recall_score(y_true, predictions, average=\"macro\") * 100:.2f}%')\n",
    "print(f'F1 Score obtida: {f1_score(y_true, predictions, average=\"macro\") * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
